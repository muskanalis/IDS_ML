# -*- coding: utf-8 -*-
"""TPU.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z-nVW27k00FgizuZzDoAtxNj8wMY8ayI
"""

!pip install --upgrade imbalanced-learn
!pip install deap
!pip install imblearn
!pip install xgboost
!pip install lightgbm
!pip install vaex



# Importing necessary library's

from sklearn.utils import shuffle
import random
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.utils import shuffle
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import FunctionTransformer
from imblearn.over_sampling import SMOTE, ADASYN
from sklearn.model_selection import cross_val_score, cross_val_predict
from deap import base, creator, tools, algorithms

"""### Considering Models"""

#importing necessary model's

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from lightgbm import LGBMClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
import xgboost as xgb
from sklearn.metrics import classification_report

from sklearn.neural_network import MLPClassifier

# To Apply -
from imblearn.ensemble import EasyEnsembleClassifier

from google.colab import drive
drive.mount('/content/drive')

# Data Loading

import pandas as pd

df = pd.read_parquet("/content/drive/MyDrive/1.Colab Notebooks/CSP_IDSML/Dataset/archive (4)/cic-collection.parquet")
df_shuffled = shuffle(df, random_state=42)
df_changedrows = df_shuffled.sample(frac=0.1, random_state=42)

df_ga = df_changedrows

X =df["Label"].value_counts()
df.Label.unique()
X.shape # total 33 classes in y
print("Each count of:", X)

"""## Plotting this imbalance of Y label"""

x_label = df["Label"].value_counts()[:10]

plt.xlabel("Classes")
plt.ylabel("Frequence")
plt.title("imbalance label distribution of our datset")
#plt.xticks(rotation=90)

plt.figure(figsize=(80,10))
plt.bar(x_label.index, x_label.values)

plt.show()

print(df_ga["Label"].value_counts())
total_label_count = df_ga["Label"].count()
print("total_label_count:", total_label_count)

df_total_900k = df_ga
df_total_900k.Label.unique()

x_label = df_ga["Label"].value_counts()[:10]

plt.xlabel("Classes")
plt.ylabel("Frequence")
plt.title("imbalance label distribution of our datset")
#plt.xticks(rotation=90)

plt.figure(figsize=(80,10))
plt.bar(x_label.index, x_label.values)

plt.show()

"""#### Feature Selection

1. Using Genetic Algortihm
(Using a new pipeline for model training)
"""

# Selecting all features from begining for use of GA

# x = df.columns
X_unfiltered = df_total_900k.drop(["ClassLabel", "Label"], axis=1) # bcz there value is very less #( "Webattack-SQLi", "DoS-Heartbleed")

# Define the labels you want to remove
labels_to_remove = ["Webattack-SQLi", "DoS-Heartbleed"]
# Filter X (the data without the unwanted labels)
X_filtered = X_unfiltered[~df_total_900k["Label"].isin(labels_to_remove)]


# Filter out rows where 'Label' is either 'Webattack-SQLi' or 'DoS-Heartbleed'
Y_filtered = df_total_900k[~df_total_900k["Label"].isin(["Webattack-SQLi", "DoS-Heartbleed"])] # only removing these two bcz of less data available.
Y = Y_filtered["Label"]
X = X_filtered
# Y = df_total_900k["Label"];

# print(X.count(), Y.count()) # After removing all the less data attributes we have same number of rows and columns that is 916750


X_columnNames = X.columns # Changing both it to columns , else as it would consider as a whole dataframe
Y_SeriesNames = Y

X_columnNames, Y_SeriesNames

"""#### Checking the count in both X and Y , which have null values here below it will come 0 as there aren't any."""

# df_ga[X_columnNames].isna().sum() # This shows no missing values for all the defined rows mentioned in X. OUTPUTS=0 for every column
# df_ga["Label"].isna().sum() # This shows no missing values for all the target variable here it is ("Label"). OUTPUTS=0 for label column

"""1. First working on the first 10k data , as the whole data is big enough -  and will take a lot of storage, time, power."""

# X_F10k = X.iloc[:10000]
# Y_F10k = Y.iloc[:10000]

# X_F10k.count(), Y_F10k.count()

"""### Converting all columns to numeric , incase some are left in the categorical format

1. Using iterating method to convert every single column present in the dataset
"""

for col in X:
    df_total_900k[col] = pd.to_numeric(df_total_900k[col], errors='coerce')

"""#### Preproccessing
1. Using MinMax Scaler
"""

X, Y

Y

scaler = MinMaxScaler()

X_Scaled = scaler.fit_transform(X)
X_Scaled

"""#### Splitting
1. Data Splitting and appying GA algorithm
"""

# Using SMOTE - To handle data imbalance fo df_ga

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_Scaled, Y)

(X_resampled.shape, y_resampled.shape)

# For NumPy arrays, use regular slicing
#(This two for GA - feature selection)
x_first1k = X_resampled[:1000]
y_first1k = y_resampled[:1000]


x_first50k = X_resampled[:50000]
y_first50k = y_resampled[:50000]
x_first50k.shape

random.seed(42)

x_train, x_test, y_train, y_test = train_test_split(x_first1k, y_first1k, train_size=0.8)

# Define the fitness function (maximize accuracy)
def evaluate(individual, x_train, y_train):
    # Convert the binary individual to a feature subset
    selected_features = [index for index, bit in enumerate(individual) if bit == 1]
    if len(selected_features) == 0:
        return 0,  # Avoid empty feature set

    x_subset = x_train[:, selected_features]
    clf = RandomForestClassifier(random_state=42)
    accuracy = cross_val_score(clf, x_subset, y_train, cv=3, scoring='accuracy').mean()

    return accuracy,

# Set up the GA
def feature_selection_ga(x_train, y_train, n_population=50, n_generations=10):
    n_features = x_train.shape[1]

    # Create the fitness and individual classes
    creator.create("FitnessMax", base.Fitness, weights=(1.0,))
    creator.create("Individual", list, fitness=creator.FitnessMax)

    # GA setup
    toolbox = base.Toolbox()
    toolbox.register("attr_bool", np.random.randint, 0, 2)
    toolbox.register("individual", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=n_features)
    toolbox.register("population", tools.initRepeat, list, toolbox.individual)

    toolbox.register("evaluate", evaluate, x_train=x_train, y_train=y_train)
    toolbox.register("mate", tools.cxTwoPoint)
    toolbox.register("mutate", tools.mutFlipBit, indpb=0.05)
    toolbox.register("select", tools.selTournament, tournsize=3)

    # Initialize population
    population = toolbox.population(n=n_population)

    # Run the algorithm (simple evolutionary algorithm)
    algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=n_generations, verbose=True)

    # Select the best individual
    best_individual = tools.selBest(population, 1)[0]
    selected_features = [index for index, bit in enumerate(best_individual) if bit == 1]
    return selected_features

selected_features = feature_selection_ga(x_train, y_train)

# Print selected features

print("Selected feature indices:", selected_features)

print("Selected feature names:", [X.columns[i] for i in selected_features])

#### Using genetic algorithm we got these selected column:
# X_SelectedColumn = ['Fwd Packet Length Max', 'Fwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s',
#                 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min',
#                 'Bwd IAT Mean', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd Header Length', 'Packet Length Max', 'Packet Length Std',
#                 'Packet Length Variance', 'URG Flag Count', 'Avg Bwd Segment Size', 'Subflow Fwd Packets', 'Init Bwd Win Bytes',
#                 'Fwd Act Data Packets', 'Active Mean', 'Active Std', 'Active Max', 'Idle Max']

X_Selected = ['Total Fwd Packets', 'Total Backward Packets', 'Bwd Packets Length Total', 'Fwd Packet Length Max', 'Fwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow IAT Std',
              'Flow IAT Max', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Fwd PSH Flags', 'Bwd Header Length', 'Fwd Packets/s',
              'Packet Length Max', 'Packet Length Mean', 'URG Flag Count', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Subflow Bwd Bytes', 'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Active Std',
              'Idle Mean', 'Idle Std', 'Idle Min']

len(X_Selected) # we got 31 Selected Column , after Using GA

X1 = X_Selected # Same as above.

Y1 = df_total_900k["Label"]

df_total_900k[X1]

df_total_900k.Label.unique(),
# np.unique(y_resampled)
x_first50k.shape
y_first50k.shape

y_first50k.value_counts()
#y_first10k
# Y.value_counts()

x_label = y_first50k.value_counts()[:10]

plt.xlabel("Classes")
plt.ylabel("Frequence")
plt.title("imbalance label distribution of our datset")
#plt.xticks(rotation=90)

plt.figure(figsize=(80,10))
plt.bar(x_label.index, x_label.values)

plt.show()

"""#### Splitting Our first 10k Dataset into train and test"""

np.random.seed(42)

x1_train, x1_test, y1_train, y1_test = train_test_split(x_first50k, y_first50k, test_size=0.2, random_state=42, stratify=y_first50k)

len(x1_train),len(x1_test) # (40000, 10000) Split complete

"""### Random Forest Classifier"""

models1 = {
    "RandomForest": RandomForestClassifier(class_weight='balanced', random_state=42),
    # "SVM": SVC(class_weight='balanced', random_state=42), removing for now as it is not performing not that well- took 15 mins and got 22 percent acccuracy
}

# Train and evaluate models
for name, model1 in models1.items():
    print("`training Score`")
    model1.fit(x1_train, y1_train)
    print(f"{name} score:", model1.score(x1_train, y1_train))
    y1rf_pred = model1.predict(x1_test)
    print("`testing Score`")
    model1.fit(x1_test, y1_test)
    print(f"{name} score:", model1.score(x1_test, y1_test))
    print(f"Model: {name}")
    print("classification_report", classification_report(y1_test, y1rf_pred))

from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support

# Evaluate the performance of the optimized stacked model
print("Optimized Stacked Model Classification Report (Averaged Metrics)")

# Calculate average precision, recall, and F1-score
precision, recall, f1_score, _ = precision_recall_fscore_support(
    y1_test, y1rf_pred, average="weighted"
)

# Print the average metrics
print(f"Average Precision: {precision:.4f}")
print(f"Average Recall: {recall:.4f}")
print(f"Average F1-Score: {f1_score:.4f}")
print("Optimized Stacked Model Accuracy:", accuracy_score(y1_test, y1rf_pred))

"""### XGBoost"""

label_encoder = LabelEncoder()
y1_train_encoded = label_encoder.fit_transform(y1_train)
y1_test_encoded = label_encoder.fit_transform(y1_test)

# Train XGBoost using the encoded labels
xgb_model = XGBClassifier(scale_pos_weight='balanced', random_state=42)
xgb_model.fit(x1_train, y1_train_encoded)

# To evaluate the model
print("XGBoost Training score:", xgb_model.score(x1_train, y1_train_encoded))
print("XGBoost Testing score:", xgb_model.score(x1_test, y1_test_encoded))

xgb_pred = xgb_model.predict(x1_test)
xgb_pred_encoded = label_encoder.fit_transform(xgb_pred)
print(f"Model: XGBoost")
print("classification_report", classification_report(y1_test_encoded, xgb_pred_encoded))

from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support

# Evaluate the performance of the optimized stacked model
print("Optimized Stacked Model Classification Report (Averaged Metrics)")

# Calculate average precision, recall, and F1-score
precision, recall, f1_score, _ = precision_recall_fscore_support(
    y1_test_encoded, xgb_pred, average="weighted"
)

# Print the average metrics
print(f"Average Precision: {precision:.4f}")
print(f"Average Recall: {recall:.4f}")
print(f"Average F1-Score: {f1_score:.4f}")
print("Optimized Stacked Model Accuracy:", accuracy_score(y1_test_encoded, xgb_pred))

"""### LGBM"""

lgbm = LGBMClassifier(boosting_type='gbdt', objective='multiclass', random_state=42)  # Change to 'multiclass' if it is a multiclass problem

print("`training Score`")
lgbm.fit(x1_train, y1_train)
print("LGBM train score:", lgbm.score(x1_train, y1_train))
y1lg_pred = lgbm.predict(x1_test)
print("`testing Score`")
lgbm.fit(x1_test, y1_test)
print("LGBM test score:", lgbm.score(x1_test, y1_test))
print("LGBM Model classification")
print("classification_report", classification_report(y1_test, y1lg_pred))

from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support

# Evaluate the performance of the optimized stacked model
print("Optimized Stacked Model Classification Report (Averaged Metrics)")

# Calculate average precision, recall, and F1-score
precision, recall, f1_score, _ = precision_recall_fscore_support(
    y1_test, y1lg_pred, average="weighted"
)

# Print the average metrics
print(f"Average Precision: {precision:.4f}")
print(f"Average Recall: {recall:.4f}")
print(f"Average F1-Score: {f1_score:.4f}")
print("Optimized Stacked Model Accuracy:", accuracy_score(y1_test, y1lg_pred))

"""### SVC"""

svc = SVC(kernel='rbf', random_state=42)

# Train the model
print("`training Score`")
svc.fit(x1_train, y1_train)
print("SVC train score:", svc.score(x1_train, y1_train))
y1svc_pred = svc.predict(x1_test)
print("`testing Score`")
svc.fit(x1_test, y1_test)
print("SVC test score:", svc.score(x1_test, y1_test))
print("SVC Model classification")
print("classification_report", classification_report(y1_test, y1svc_pred))

from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support

# Evaluate the performance of the optimized stacked model
print("Optimized Stacked Model Classification Report (Averaged Metrics)")

# Calculate average precision, recall, and F1-score
precision, recall, f1_score, _ = precision_recall_fscore_support(
    y1_test, y1svc_pred, average="weighted"
)

# Print the average metrics
print(f"Average Precision: {precision:.4f}")
print(f"Average Recall: {recall:.4f}")
print(f"Average F1-Score: {f1_score:.4f}")
print("Optimized Stacked Model Accuracy:", accuracy_score(y1_test, y1svc_pred))

"""## MLP"""

mlp = MLPClassifier(hidden_layer_sizes=(100, 50),  # 2 hidden layers with 100 and 50 neurons
                    activation='relu',             # Activation function: 'relu', can also try 'tanh', 'logistic'
                    solver='adam',                 # Optimizer: 'adam', can also try 'sgd'
                    random_state=42,
                    max_iter=500)

mlp.fit(x1_train, y1_train)
print("MLP Training Score", mlp.score(x1_train, y1_train))

print("MLP Testing Score", mlp.score(x1_test, y1_test))

y1mlp_pred = mlp.predict(x1_test)

print("MLP Model classification")
print("classification_report", classification_report(y1_test, y1mlp_pred))

"""## Calculating Precision , Recall , F-1 Score"""

from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support

# Evaluate the performance of the optimized stacked model
print("Optimized Stacked Model Classification Report (Averaged Metrics)")

# Calculate average precision, recall, and F1-score
precision, recall, f1_score, _ = precision_recall_fscore_support(
    y1_test, y1mlp_pred, average="weighted"
)

# Print the average metrics
print(f"Average Precision: {precision:.4f}")
print(f"Average Recall: {recall:.4f}")
print(f"Average F1-Score: {f1_score:.4f}")
print("Optimized Stacked Model Accuracy:", accuracy_score(y1_test, y1mlp_pred))

"""## Creating a stacking technique, For Hybrid approach"""

# Label Encoding
label_encoder = LabelEncoder()
y1_train_encoded = label_encoder.fit_transform(y1_train)
y1_test_encoded = label_encoder.transform(y1_test)

xgb_model = XGBClassifier(random_state=42)
rf_model = RandomForestClassifier(random_state=42)
mlp_model = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', random_state=42, max_iter=500)

xgb_model.fit(x1_train, y1_train_encoded)
rf_model.fit(x1_train, y1_train)
mlp_model.fit(x1_train, y1_train)

xgb_pred = cross_val_predict(xgb_model, x1_train, y1_train_encoded, cv=5, method="predict")
rf_pred = cross_val_predict(rf_model, x1_train, y1_train_encoded, cv=5, method="predict")
mlp_pred = cross_val_predict(mlp_model, x1_train, y1_train_encoded, cv=5, method="predict")

# Stack predictions to create a new feature set for the meta-model
stacked_features_train = np.column_stack((xgb_pred, rf_pred, mlp_pred))

# Meta-Model
meta_model = LogisticRegression()
meta_model.fit(stacked_features_train, y1_train_encoded)

# Get the unique labels from training data after encoding
unique_labels = label_encoder.classes_

# Function to safely transform predictions, handling any unseen labels
def safe_transform(predictions):
    return [label_encoder.transform([pred])[0] if pred in unique_labels else -1 for pred in predictions]

# Make predictions and safely encode
xgb_test_pred = safe_transform(xgb_model.predict(x1_test))
rf_test_pred = safe_transform(rf_model.predict(x1_test))
mlp_test_pred = safe_transform(mlp_model.predict(x1_test))

# Stack test predictions for the meta-model
stacked_features_test = np.column_stack((xgb_test_pred, rf_test_pred, mlp_test_pred))

# Use the meta-model to make the final predictions
final_predictions_encoded = meta_model.predict(stacked_features_test)

# Decode final predictions for evaluation
final_predictions = label_encoder.inverse_transform(final_predictions_encoded)

# Evaluate the model's performance
print("Stacked Model Classification Report")
print(classification_report(y1_test, final_predictions))
print("Stacked Model Accuracy:", accuracy_score(y1_test, final_predictions))

"""## Primarily we are getting a accuracy of 78% on the test data set on the meta model.

# **Going with a different approach for better optimization**
"""

# Obtain probability predictions for stacking
xgb_pred_proba = cross_val_predict(xgb_model, x1_train, y1_train_encoded, cv=5, method="predict_proba")
rf_pred_proba = cross_val_predict(rf_model, x1_train, y1_train_encoded, cv=5, method="predict_proba")
mlp_pred_proba = cross_val_predict(mlp_model, x1_train, y1_train_encoded, cv=5, method="predict_proba")

# Stack probabilities for meta-model training
stacked_features_train = np.hstack((xgb_pred_proba, rf_pred_proba, mlp_pred_proba))

# Use a more powerful meta-model (e.g., XGBoost)
meta_model = XGBClassifier(random_state=42)
meta_model.fit(stacked_features_train, y1_train_encoded)

# Predict on test set using probability stacking
xgb_test_pred_proba = xgb_model.predict_proba(x1_test)
rf_test_pred_proba = rf_model.predict_proba(x1_test)
mlp_test_pred_proba = mlp_model.predict_proba(x1_test)

stacked_features_test = np.hstack((xgb_test_pred_proba, rf_test_pred_proba, mlp_test_pred_proba))
final_predictions_encoded = meta_model.predict(stacked_features_test)
final_predictions = label_encoder.inverse_transform(final_predictions_encoded)

# Evaluate the performance of the optimized stacked model
print("Optimized Stacked Model Classification Report")
print(classification_report(y1_test, final_predictions))
print("Optimized Stacked Model Accuracy:", accuracy_score(y1_test, final_predictions))

from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support

# Evaluate the performance of the optimized stacked model
print("Optimized Stacked Model Classification Report (Averaged Metrics)")

# Calculate average precision, recall, and F1-score
precision, recall, f1_score, _ = precision_recall_fscore_support(
    y1_test, final_predictions, average="weighted"
)

# Print the average metrics
print(f"Average Precision: {precision:.4f}")
print(f"Average Recall: {recall:.4f}")
print(f"Average F1-Score: {f1_score:.4f}")
print("Optimized Stacked Model Accuracy:", accuracy_score(y1_test, final_predictions))

"""# **after Optimizing, using a non-linear meta model, we got an final accuracy score of 98%**

#### ________________________THExEND__________________________________________________________________________________

# **This Section uses correlation matrix for feature selection**
"""

#### Using SMOTE - To handle data imbalance

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(df_ga[X1], Y1)

#Features to remove: ['Bwd Packets Length Total', 'Fwd Packet Length Std', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd Packets/s', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'SYN Flag Count', 'Avg Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Fwd Act Data Packets', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max']
# Remaining features after filtering: Index(['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',
#        'Fwd Packets Length Total', 'Fwd Packet Length Max',
#        'Fwd Packet Length Mean', 'Bwd Packet Length Max', 'Flow Bytes/s',
#        'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Bwd IAT Total',
#        'Bwd IAT Mean', 'Bwd IAT Std', 'Fwd PSH Flags', 'Fwd Header Length',
#        'Bwd Header Length', 'Bwd Packets/s', 'URG Flag Count',
#        'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Seg Size Min',
#        'Active Mean', 'Active Std', 'Idle Min'],
#       dtype='object')

df_trial = df

numeric_df = df.select_dtypes(['object'])                                        # We can see in our dataframe we only have these two String type columns (Which thus becomes our target column here we are considering ["Label"])
numeric_df.head()

# setting up the target variable and feature variable
np.random.seed(42)

x1 = ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets',
       'Fwd Packets Length Total', 'Fwd Packet Length Max',
       'Fwd Packet Length Mean', 'Bwd Packet Length Max', 'Flow Bytes/s',
       'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Bwd IAT Total',
       'Bwd IAT Mean', 'Bwd IAT Std', 'Fwd PSH Flags', 'Fwd Header Length',
       'Bwd Header Length', 'Bwd Packets/s', 'URG Flag Count',
       'Init Fwd Win Bytes', 'Init Bwd Win Bytes', 'Fwd Seg Size Min',
       'Active Mean', 'Active Std', 'Idle Min']

y1 = df_trial['Label']

# for col in x1:
#     df_trial[col] = pd.to_numeric(df_trial[col], errors='coerce')

# scaler = MinMaxScaler()

# df_trial[x1] = scaler.fit_transform(df_trial[x1])

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(df_trial[x1], y1)

# after using SMOTE >>>
y_resampled.count()  # output - 237144237
X_resampled.count()  # output - 237144237

"""## The actual data has millions of rows, training on whole model would take significant amount of time, and computation cost.

##So we are training on first 10k model to check how is our model performing.

###### Unique classes in y_first10k: ['Benign' 'Botnet' 'Bruteforce-FTP' 'Bruteforce-SSH' 'DDoS' 'DDoS-DNS', 'DDoS-Ddossim' 'DDoS-HOIC' 'DDoS-LDAP' 'DDoS-LOIC-HTTP' 'DDoS-MSSQL''DDoS-NTP' 'DDoS-NetBIOS' 'DDoS-SNMP' 'DDoS-Slowloris' 'DDoS-Syn''DDoS-TFTP' 'DDoS-UDP' 'DDoS-UDPLag' 'DoS-Goldeneye' 'DoS-Heartbleed''DoS-Hulk' 'DoS-Rudy' 'DoS-Slowbody' 'DoS-Slowheaders' 'DoS-Slowhttptest''DoS-Slowloris' 'DoS-Slowread' 'Infiltration' 'Portscan' 'Webattack-SQLi''Webattack-XSS' 'Webattack-bruteforce']
"""

# df_trial[x1].head()

# trying to Reshuffle

#X_shuffled, y_shuffled = shuffle(X_resampled, y_resampled, random_state=42)

# Select the first 10,000 rows after shuffling
x1_first10k = X_shuffled[:10000]
y1_first10k = y_shuffled[:10000]

# Verify if all unique labels are present in the first 10k rows
print("Unique classes in y_first10k:", np.unique(y1_first10k))

# Unique classes in y_first10k: ['Benign' 'Botnet' 'Bruteforce-FTP' 'Bruteforce-SSH' 'DDoS' 'DDoS-DNS'
#  'DDoS-Ddossim' 'DDoS-HOIC' 'DDoS-LDAP' 'DDoS-LOIC-HTTP' 'DDoS-MSSQL'
#  'DDoS-NTP' 'DDoS-NetBIOS' 'DDoS-SNMP' 'DDoS-Slowloris' 'DDoS-Syn'
#  'DDoS-TFTP' 'DDoS-UDP' 'DDoS-UDPLag' 'DoS-Goldeneye' 'DoS-Heartbleed'
#  'DoS-Hulk' 'DoS-Rudy' 'DoS-Slowbody' 'DoS-Slowheaders' 'DoS-Slowhttptest'
#  'DoS-Slowloris' 'DoS-Slowread' 'Infiltration' 'Portscan' 'Webattack-SQLi'
#  'Webattack-XSS' 'Webattack-bruteforce']

# x_first10k = X_resampled.iloc[:237144237]
# y_first10k = y_resampled.iloc[:237144237]

# y_first10k.head()

# smote = SMOTE(random_state=42)
# X_resampled, y_resampled = smote.fit_resample(x_first10k, y_first10k)

np.random.seed(42)

x1_train, x1_test, y1_train, y1_test = train_test_split(x1_first10k, y1_first10k, test_size=0.2, random_state=42, stratify=y1_first10k)

#y1_train.count()

"""### Only RandomForest and SVM"""

models = {
    "RandomForest": RandomForestClassifier(class_weight='balanced', random_state=42),
    "SVM": SVC(class_weight='balanced', random_state=42),
}

# Train and evaluate models
for name, model in models.items():
    model.fit(x1_train, y1_train)
    print(f"{name} score:", model.score(x1_train, y1_train))
    y1_pred = model.predict(x1_test)
    print(f"Model: {name}")
    print(classification_report(y1_test, y1_pred))

"""### XGBoost"""

# Now reshuffle and select the first 10k rows as before
#X_shuffled, y_shuffled = shuffle(X_resampled, y_resampled, random_state=42)

# previously we have the data ->

# x1_first10k.count(), y1_first10k.count()


# Select the first 10,000 rows after shuffling
# x_first10k_XGB = X_shuffled[:10000]
# y_first10k_XGB = y_shuffled[:10000]

# x1_train_xgb, x1_test_xgb, y1_train_xgb, y1_test_xgb = train_test_split(x_first10k_XGB, y_first10k_XGB, test_size=0.2, random_state=42, stratify=y_first10k_XGB)


# Label-Encoding

label_encoder = LabelEncoder()
y_first10k_encoded = label_encoder.fit_transform(y1_first10k)


# Train XGBoost using the encoded labels
xgb_model = XGBClassifier(scale_pos_weight='balanced', random_state=42)
xgb_model.fit(x1_first10k, y_first10k_encoded)

# To evaluate the model
print("XGBoost score:", xgb_model.score(x1_first10k, y_first10k_encoded))

